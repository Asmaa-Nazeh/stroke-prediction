# ğŸ§  Stroke Prediction Using Machine Learning

This project aims to predict whether a person is likely to have a stroke based on various health and demographic features. It is a binary classification task using several machine learning models to identify the best-performing one.

## ğŸ“Š Dataset

The dataset used includes features such as:

- gender
- age
- hypertension
- heart_disease
- ever_married
- work_type
- Residence_type
- avg_glucose_level
- bmi
- smoking_status
- stroke (Target Variable)

ğŸ“Œ *Source*: [Kaggle Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset)

---

## â“ Questions & Data Analysis

During Exploratory Data Analysis (EDA), I explored the following questions:

1. *Is the data imbalanced in terms of stroke cases?*
   - âœ… Yes, the data is highly imbalanced, and this was visualized using a bar plot.
   - ğŸ”§ Solved using *SMOTE* oversampling technique.

2. *What are the distributions of features like age, BMI, and glucose level?*
   - ğŸ“Š Visualized using histograms and boxplots.
   - ğŸ” Identified outliers and missing values.

3. *How are stroke cases related to categorical variables (gender, work type, marital status, etc.)?*
   - ğŸ“ˆ Analyzed using countplots and pie charts.

4. **What are the most correlated features with the target variable stroke?**
   - ğŸ§  Used correlation heatmap after encoding to select important features.

5. *How do the models perform based on key classification metrics?*
   - âœ” Compared multiple models using Accuracy, Precision, Recall, and F1-Score.

---

## ğŸ›  Preprocessing Steps

- âœ… Handled missing values in bmi
- âœ… Detected and treated outliers using boxplots
- âœ… Encoded categorical features with LabelEncoder
- âœ… Feature selection using correlation analysis
- âœ… Feature scaling using StandardScaler
- âœ… Balanced the dataset using *SMOTE*

---

## ğŸ“ˆ Models Used

- Naive Bayes
- K-Nearest Neighbors (KNN)
- Decision Tree
- Random Forest
- Support Vector Machine (SVM)
- Logistic Regression

---

## âœ… Evaluation Metrics

Each model was evaluated based on the following metrics:

- *Accuracy*
- *Precision*
- *Recall*
- *F1-Score*

ğŸ“Š Results were displayed in:
- Tabular format
- Bar charts for visual comparison
- Confusion matrix and classification report (especially for the best model)

---

## â­ Best Model

The *Random Forest* classifier showed the best performance and was selected for final evaluation:

- High accuracy
- Balanced precision and recall
- Good F1-Score

---

## ğŸ“· Visualizations

- ğŸ”¥ Correlation heatmap
- ğŸ“Š Countplots and pie charts for categorical variables
- ğŸ“‰ Boxplots for numeric features (age, glucose, BMI)
- ğŸ“¦ Stroke distribution (before and after SMOTE)
- ğŸ“‹ Confusion Matrix and Classification Report
- ğŸ“ˆ Bar plots comparing model performance

---

## ğŸ“š Requirements

Install dependencies:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn